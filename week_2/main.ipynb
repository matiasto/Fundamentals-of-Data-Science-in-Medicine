{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64943cf-7525-4a2a-a2fe-ad6496ccd3a2",
   "metadata": {},
   "source": [
    "# MAM02 - Week 2\n",
    "*Authors*: Robin & Matias\n",
    "\n",
    "*Status*: Draft\n",
    "\n",
    "*Date*: 8.10.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c83d5-4e43-46b4-9d80-e98deeb142a4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this analysis, we aim to investigate the association between 20 risk factors and the occurrence of cardiovascular disease (CVD) events in patients with familial hypercholesterolemia (FH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19ec880-0bc9-4220-9d3b-c7aa7095d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex  height  weight        bmi alcoholuse smoking  systbp  diasbp  \\\n",
      "0  female   174.0    77.0  25.432686         no    Ever   140.0    95.0   \n",
      "1    male   179.0    65.0  20.286508        yes    Ever   140.0    95.0   \n",
      "2    male   183.0    85.0  25.381469        yes    Ever   130.0    85.0   \n",
      "3  female   169.0    63.0  22.058051        yes    Ever   130.0    75.0   \n",
      "4    male   176.0    88.0  28.409091        yes   Never   120.0    80.0   \n",
      "\n",
      "  hypertension  Glucose  ...  diabetes familiarHC     Tc   HDL    Tg    Lpa  \\\n",
      "0          yes      4.7  ...      ever        yes  11.22  1.00  1.40    NaN   \n",
      "1           no      4.5  ...      ever         no  11.50  1.04  0.81  740.0   \n",
      "2           no      4.7  ...      ever         no  11.36  1.64  1.67    NaN   \n",
      "3           no      4.6  ...      ever         no  10.21  1.07  1.18    NaN   \n",
      "4           no      5.4  ...      ever         no  10.09  1.69  1.01    NaN   \n",
      "\n",
      "   homocysteine  creatinine        age  event  \n",
      "0          12.1        75.0  65.916496   none  \n",
      "1           NaN        66.0  31.115674    yes  \n",
      "2           NaN        79.0  47.791923    yes  \n",
      "3           NaN        58.0  65.672827   none  \n",
      "4           NaN        63.0  42.318960   none  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   sex           2400 non-null   category\n",
      " 1   height        2080 non-null   float64 \n",
      " 2   weight        2195 non-null   float64 \n",
      " 3   bmi           2058 non-null   float64 \n",
      " 4   alcoholuse    1909 non-null   category\n",
      " 5   smoking       2166 non-null   category\n",
      " 6   systbp        2363 non-null   float64 \n",
      " 7   diasbp        2363 non-null   float64 \n",
      " 8   hypertension  2376 non-null   category\n",
      " 9   Glucose       2282 non-null   float64 \n",
      " 10  Hba1c         1470 non-null   float64 \n",
      " 11  diabetes      2400 non-null   category\n",
      " 12  familiarHC    2400 non-null   category\n",
      " 13  Tc            2152 non-null   float64 \n",
      " 14  HDL           1960 non-null   float64 \n",
      " 15  Tg            2026 non-null   float64 \n",
      " 16  Lpa           1698 non-null   float64 \n",
      " 17  homocysteine  1094 non-null   float64 \n",
      " 18  creatinine    2329 non-null   float64 \n",
      " 19  age           2400 non-null   float64 \n",
      " 20  event         2400 non-null   category\n",
      "dtypes: category(7), float64(14)\n",
      "memory usage: 279.9 KB\n",
      "None\n",
      "            height       weight          bmi       systbp       diasbp  \\\n",
      "count  2080.000000  2195.000000  2058.000000  2363.000000  2363.000000   \n",
      "mean    172.467308    74.933030    25.111342   135.003386    81.913246   \n",
      "std       9.304474    13.372804     3.576671    19.458503    10.516614   \n",
      "min     145.000000    41.000000    -1.000000    80.000000    30.000000   \n",
      "25%     165.000000    65.000000    22.724403   120.000000    75.000000   \n",
      "50%     172.000000    74.000000    24.751459   130.000000    80.000000   \n",
      "75%     179.000000    83.000000    27.143037   145.000000    90.000000   \n",
      "max     202.000000   155.000000    47.194008   225.000000   140.000000   \n",
      "\n",
      "           Glucose        Hba1c           Tc          HDL           Tg  \\\n",
      "count  2282.000000  1470.000000  2152.000000  1960.000000  2026.000000   \n",
      "mean      5.079251     5.787830     9.534693     1.210087     1.804919   \n",
      "std       1.020495     1.236499     2.002673     0.354308     1.029021   \n",
      "min       2.800000     2.400000     3.530000     0.360000     0.360000   \n",
      "25%       4.500000     5.100000     8.107500     0.977500     1.100000   \n",
      "50%       4.900000     5.500000     9.200000     1.160000     1.580000   \n",
      "75%       5.400000     6.100000    10.600000     1.400000     2.200000   \n",
      "max      19.400000    16.500000    18.300000     3.950000    10.810000   \n",
      "\n",
      "               Lpa  homocysteine   creatinine          age  \n",
      "count  1698.000000   1094.000000  2329.000000  2400.000000  \n",
      "mean    337.916372     12.445899    81.271790    47.067383  \n",
      "std     418.173833      8.867317    15.524963    12.184997  \n",
      "min       4.000000      4.000000    37.000000    18.061602  \n",
      "25%      60.000000      9.000000    71.000000    37.930185  \n",
      "50%     166.000000     11.000000    80.000000    46.238193  \n",
      "75%     470.750000     13.800000    90.000000    55.542779  \n",
      "max    3381.000000    215.000000   191.000000    85.809719  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the given data file\n",
    "data = pd.read_spss(\"GIRAFH.SAV\")\n",
    "\n",
    "# Some general data descriptions\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be476ae9-8515-4e77-989e-dfaa004686f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                0\n",
      "height           320\n",
      "weight           205\n",
      "bmi              342\n",
      "alcoholuse       491\n",
      "smoking          234\n",
      "systbp            37\n",
      "diasbp            37\n",
      "hypertension      24\n",
      "Glucose          118\n",
      "Hba1c            930\n",
      "diabetes           0\n",
      "familiarHC         0\n",
      "Tc               248\n",
      "HDL              440\n",
      "Tg               374\n",
      "Lpa              702\n",
      "homocysteine    1306\n",
      "creatinine        71\n",
      "age                0\n",
      "event              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc6163-8d31-4d1b-97fc-c8f03e5a5601",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "*Discarding Missing Values* can lead to losing essential information, especially if missingness is not completely random.\n",
    "*Multiple Imputation* preserves the dataset's size by filling in the missing values based on other available data\n",
    "\n",
    "*Chosen Method*: Multiple Imputation\n",
    "\n",
    "*Rationale*: Given the size of the dataset (2,400 patients) and the potential loss of information, we choose multiple imputation to handle missing values. We believe this method allows us to use all available data better and reduce the bias that might result from simply discarding missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fccb7d4-985f-40df-9743-6fb7521477c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "imputer_freq = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "continuous_vars = ['height', 'weight', 'bmi', 'systbp', 'diasbp', 'Glucose', 'Hba1c', 'Tc', 'HDL', 'Tg', 'Lpa', 'homocysteine', 'creatinine', 'age']\n",
    "categorical_vars = ['sex', 'alcoholuse', 'smoking', 'hypertension', 'diabetes', 'familiarHC', 'event']\n",
    "\n",
    "data[continuous_vars] = imputer_mean.fit_transform(data[continuous_vars])\n",
    "\n",
    "data[categorical_vars] = imputer_freq.fit_transform(data[categorical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8232be7-fc3a-48e6-a86d-ce2e8e6f74ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex             0\n",
      "height          0\n",
      "weight          0\n",
      "bmi             0\n",
      "alcoholuse      0\n",
      "smoking         0\n",
      "systbp          0\n",
      "diasbp          0\n",
      "hypertension    0\n",
      "Glucose         0\n",
      "Hba1c           0\n",
      "diabetes        0\n",
      "familiarHC      0\n",
      "Tc              0\n",
      "HDL             0\n",
      "Tg              0\n",
      "Lpa             0\n",
      "homocysteine    0\n",
      "creatinine      0\n",
      "age             0\n",
      "event           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8509084-f109-4177-9f9a-ad2ec72b672d",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Compare the means of continuous variables between the event and no-event groups using t-tests to identify significant differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551eed36-1be7-4726-8dbb-0a987af516cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Variable  Event Mean  No Event Mean       P-Value\n",
      "0         height  172.340862     172.528421  6.191569e-01\n",
      "1         weight   76.434827      74.207192  6.203391e-05\n",
      "2            bmi   25.631893      24.859753  7.984809e-08\n",
      "3         systbp  138.245550     133.436406  9.645333e-09\n",
      "4         diasbp   83.395754      81.196731  1.241415e-06\n",
      "5        Glucose    5.321026       4.962398  7.917314e-17\n",
      "6          Hba1c    5.972410       5.698620  6.852495e-11\n",
      "7             Tc    9.668917       9.469821  1.589363e-02\n",
      "8            HDL    1.160368       1.234116  1.141435e-07\n",
      "9             Tg    2.005692       1.707883  3.584563e-13\n",
      "10           Lpa  407.589526     304.242450  1.226179e-11\n",
      "11  homocysteine   13.153659      12.103829  5.508880e-05\n",
      "12    creatinine   84.471159      79.725495  8.022937e-13\n",
      "13           age   48.419700      46.413791  1.541438e-04\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "event_data = data[data['event'] == 'yes']\n",
    "no_event_data = data[data['event'] == 'none']\n",
    "\n",
    "def create_summary_table(var_list):\n",
    "    # Initialize an empty list to store rows\n",
    "    rows = []\n",
    "    for var in var_list:\n",
    "        event_mean = event_data[var].mean()\n",
    "        no_event_mean = no_event_data[var].mean()\n",
    "        #  t-test\n",
    "        t_stat, p_val = ttest_ind(event_data[var], no_event_data[var], nan_policy='omit')\n",
    "\n",
    "        row = {'Variable': var,\n",
    "               'Event Mean': event_mean,\n",
    "               'No Event Mean': no_event_mean,\n",
    "               'P-Value': p_val}\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    summary_table = pd.DataFrame(rows)\n",
    "    return summary_table\n",
    "\n",
    "summary_continuous = create_summary_table(continuous_vars)\n",
    "print(summary_continuous)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bd081-dd25-4507-9ed9-9f96acc04beb",
   "metadata": {},
   "source": [
    "For categorical variables, we use chi-squared tests to compare the proportions between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2837d6b-c613-49a4-bb05-f7f912c0cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variable                                   Event Proportion  \\\n",
      "0           sex  {'male': 0.6227621483375959, 'female': 0.37723...   \n",
      "1    alcoholuse  {'yes': 0.7864450127877238, 'no': 0.2135549872...   \n",
      "2       smoking  {'Ever': 0.8414322250639387, 'Never': 0.158567...   \n",
      "3  hypertension  {'no': 0.8286445012787724, 'yes': 0.1713554987...   \n",
      "4      diabetes  {'ever': 0.8887468030690537, 'never': 0.111253...   \n",
      "5    familiarHC  {'no': 0.840153452685422, 'yes': 0.15984654731...   \n",
      "6         event                                       {'yes': 1.0}   \n",
      "\n",
      "                                 No Event Proportion       P-Value  \n",
      "0  {'female': 0.5716934487021014, 'male': 0.42830...  6.255881e-19  \n",
      "1  {'yes': 0.7966625463535228, 'no': 0.2033374536...  5.991600e-01  \n",
      "2  {'Ever': 0.7255871446229913, 'Never': 0.274412...  5.406920e-10  \n",
      "3  {'no': 0.9406674907292955, 'yes': 0.0593325092...  4.554371e-18  \n",
      "4  {'ever': 0.9684796044499382, 'never': 0.031520...  7.813679e-15  \n",
      "5  {'no': 0.7663782447466008, 'yes': 0.2336217552...  3.984244e-05  \n",
      "6                                      {'none': 1.0}  0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def create_categorical_summary(var_list):\n",
    "    rows = []\n",
    "    for var in var_list:\n",
    "        event_counts = event_data[var].value_counts(normalize=True)\n",
    "        no_event_counts = no_event_data[var].value_counts(normalize=True)\n",
    "\n",
    "        # use the chi for the categorical only\n",
    "        contingency_table = pd.crosstab(data[var], data['event'])\n",
    "        chi2, p_val, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "        row = {'Variable': var,\n",
    "               'Event Proportion': event_counts.to_dict(),\n",
    "               'No Event Proportion': no_event_counts.to_dict(),\n",
    "               'P-Value': p_val}\n",
    "        rows.append(row)\n",
    "\n",
    "    summary_table = pd.DataFrame(rows)\n",
    "    return summary_table\n",
    "\n",
    "\n",
    "summary_categorical = create_categorical_summary(categorical_vars)\n",
    "\n",
    "\n",
    "print(summary_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bf0c3-74cf-4aff-8e92-ce9c037e8835",
   "metadata": {},
   "source": [
    "## Univariate Logistic Regression Analyses\n",
    "\n",
    "#### Performing Univariate Analyses\n",
    "\n",
    "We first need to preprocess the categorical variables so that they're ready for further computation, we need to avoid the current string format of the values. This means the next step for each categorical variable is to transform the string values to numeric ones, that correspond to a unique integer ID representative of each distinct category. This process is called label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf5b7e0-1b82-43b4-93de-49538f51973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sex           2400 non-null   int64  \n",
      " 1   height        2400 non-null   float64\n",
      " 2   weight        2400 non-null   float64\n",
      " 3   bmi           2400 non-null   float64\n",
      " 4   alcoholuse    2400 non-null   int64  \n",
      " 5   smoking       2400 non-null   int64  \n",
      " 6   systbp        2400 non-null   float64\n",
      " 7   diasbp        2400 non-null   float64\n",
      " 8   hypertension  2400 non-null   int64  \n",
      " 9   Glucose       2400 non-null   float64\n",
      " 10  Hba1c         2400 non-null   float64\n",
      " 11  diabetes      2400 non-null   int64  \n",
      " 12  familiarHC    2400 non-null   int64  \n",
      " 13  Tc            2400 non-null   float64\n",
      " 14  HDL           2400 non-null   float64\n",
      " 15  Tg            2400 non-null   float64\n",
      " 16  Lpa           2400 non-null   float64\n",
      " 17  homocysteine  2400 non-null   float64\n",
      " 18  creatinine    2400 non-null   float64\n",
      " 19  age           2400 non-null   float64\n",
      " 20  event         2400 non-null   int64  \n",
      "dtypes: float64(14), int64(7)\n",
      "memory usage: 393.9 KB\n",
      "None\n",
      "   sex  height  weight        bmi  alcoholuse  smoking  systbp  diasbp  \\\n",
      "0    0   174.0    77.0  25.432686           0        0   140.0    95.0   \n",
      "1    1   179.0    65.0  20.286508           1        0   140.0    95.0   \n",
      "2    1   183.0    85.0  25.381469           1        0   130.0    85.0   \n",
      "3    0   169.0    63.0  22.058051           1        0   130.0    75.0   \n",
      "4    1   176.0    88.0  28.409091           1        1   120.0    80.0   \n",
      "\n",
      "   hypertension  Glucose  ...  diabetes  familiarHC     Tc   HDL    Tg  \\\n",
      "0             1      4.7  ...         0           1  11.22  1.00  1.40   \n",
      "1             0      4.5  ...         0           0  11.50  1.04  0.81   \n",
      "2             0      4.7  ...         0           0  11.36  1.64  1.67   \n",
      "3             0      4.6  ...         0           0  10.21  1.07  1.18   \n",
      "4             0      5.4  ...         0           0  10.09  1.69  1.01   \n",
      "\n",
      "          Lpa  homocysteine  creatinine        age  event  \n",
      "0  337.916372     12.100000        75.0  65.916496      0  \n",
      "1  740.000000     12.445899        66.0  31.115674      1  \n",
      "2  337.916372     12.445899        79.0  47.791923      1  \n",
      "3  337.916372     12.445899        58.0  65.672827      0  \n",
      "4  337.916372     12.445899        63.0  42.318960      0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_encoded = data.copy()\n",
    "for category in categorical_vars:\n",
    "    data_encoded[category] = le.fit_transform(data_encoded[category])\n",
    "\n",
    "print(data_encoded.info())\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7640d2d-8d78-4992-8f65-29a508fc60cf",
   "metadata": {},
   "source": [
    "### We chose logistic regression\n",
    "\n",
    "Rationale: Linear regression is for regression. Logistic regression for classification. Logistic regression is called a regression nonetheless, since in principle it is very close to the concept of linear regression. The difference is that the linear combination of the feature vector and the coefficient vector βᵀx is then passed through the sigmoid function in order to transform the range of returned values from (-∞, +∞) to [0, 1]. This particularly useful trait makes logistic regression perfect for binary classification tasks which is the case in this one (event: yes/no)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0c800-c148-4ca1-b9a2-501da553c333",
   "metadata": {},
   "source": [
    "Next, we are going to loop through each predictor variable, build the model, and calculate some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d883b18-79c7-48b4-b702-ab4a8bd2194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Variable  Odds Ratio       P-Value  95% CI Lower  95% CI Upper\n",
      "0         height    0.997501  6.190016e-01      0.987711      1.007387\n",
      "1         weight    1.013556  7.010999e-05      1.006851      1.020306\n",
      "2            bmi    1.072825  1.191089e-07      1.045270      1.101108\n",
      "3         systbp    1.012798  1.473752e-08      1.008352      1.017264\n",
      "4         diasbp    1.020437  1.523080e-06      1.012056      1.028887\n",
      "5        Glucose    1.477631  4.298073e-14      1.335232      1.635217\n",
      "6          Hba1c    1.335813  8.573775e-10      1.217773      1.465294\n",
      "7             Tc    1.056188  1.608361e-02      1.010205      1.104265\n",
      "8            HDL    0.460673  1.536473e-07      0.344893      0.615321\n",
      "9             Tg    1.382158  3.981479e-12      1.261391      1.514488\n",
      "10           Lpa    1.000799  1.109277e-10      1.000556      1.001042\n",
      "11  homocysteine    1.044978  1.721842e-04      1.021265      1.069241\n",
      "12    creatinine    1.020444  3.255071e-12      1.014650      1.026271\n",
      "13           age    1.013578  1.632321e-04      1.006496      1.020709\n",
      "14           sex    2.203512  8.661195e-19      1.849854      2.624783\n",
      "15    alcoholuse    0.939943  5.623621e-01      0.762257      1.159050\n",
      "16       smoking    0.498289  6.251416e-10      0.399576      0.621387\n",
      "17  hypertension    3.278485  5.319923e-17      2.483452      4.328033\n",
      "18      diabetes    3.846212  1.409428e-13      2.691447      5.496431\n",
      "19    familiarHC    0.624129  3.494786e-05      0.499252      0.780242\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "univariate_results_list = []\n",
    "\n",
    "\n",
    "for var in continuous_vars + categorical_vars:\n",
    "    if var != 'event':\n",
    "        model = sm.Logit(data_encoded['event'], sm.add_constant(data_encoded[var]))\n",
    "        result = model.fit(disp=0)\n",
    "        \n",
    "        odds_ratio = np.exp(result.params.iloc[1])\n",
    "        p_value = result.pvalues.iloc[1]\n",
    "        conf = result.conf_int()\n",
    "        lower_ci = np.exp(conf.iloc[1, 0])\n",
    "        upper_ci = np.exp(conf.iloc[1, 1])\n",
    "        \n",
    "        univariate_results_list.append({'Variable': var,\n",
    "                                        'Odds Ratio': odds_ratio,\n",
    "                                        'P-Value': p_value,\n",
    "                                        '95% CI Lower': lower_ci,\n",
    "                                        '95% CI Upper': upper_ci})\n",
    "\n",
    "univariate_results = pd.DataFrame(univariate_results_list)\n",
    "print(univariate_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91273de-0959-4484-992c-19f5b5be21c8",
   "metadata": {},
   "source": [
    "## Multivariable Logistic Regression Model\n",
    "\n",
    "\n",
    "We first include all predictor variables in the multivariable logistic regression model to assess their combined effect on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40dfd785-c890-4864-a39c-12cd715e07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551286\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "predictors = data_encoded.drop(columns=['event'])\n",
    "\n",
    "predictors = sm.add_constant(predictors)\n",
    "\n",
    "# Build the logistic regression model\n",
    "model = sm.Logit(data_encoded['event'], predictors)\n",
    "multivar_result = model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7ae89-ca13-456f-94aa-4a1ceb9fa2e2",
   "metadata": {},
   "source": [
    "#### Checking for Multicollinearity\n",
    "\n",
    "Multicollinearity among predictors can inflate the variance of coefficient estimates and make the model unstable. We calculate the VIF to detect multicollinearity. Variables with VIF > 5 may need to be removed or combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61286e3-ea74-42af-af1c-75c96745e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature          VIF\n",
      "0          const  2370.531062\n",
      "1            sex     2.194665\n",
      "2         height     5.512755\n",
      "3         weight    12.308550\n",
      "4            bmi     7.879261\n",
      "5     alcoholuse     1.057499\n",
      "6        smoking     1.041734\n",
      "7         systbp     2.008979\n",
      "8         diasbp     1.903956\n",
      "9   hypertension     1.154098\n",
      "10       Glucose     1.541073\n",
      "11         Hba1c     1.167913\n",
      "12      diabetes     1.515626\n",
      "13    familiarHC     1.023789\n",
      "14            Tc     1.053018\n",
      "15           HDL     1.226671\n",
      "16            Tg     1.277541\n",
      "17           Lpa     1.012756\n",
      "18  homocysteine     1.015721\n",
      "19    creatinine     1.465287\n",
      "20           age     1.335832\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = predictors.columns\n",
    "\n",
    "# Calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i)\n",
    "                   for i in range(len(predictors.columns))]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b2614-4b99-4a23-87a6-7f557952813b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
